---
layout: post
title: "People Analytics and the Big Data Dystopia"
description: "The dystopian future and the transition from freedom and employment to compliance and deployment thanks to big data and people analytics."
tagline: "future"
category: future
tags: [future, big data, analytics, employment, big brother, privacy, anonymity, compliance]
related: [Step Away From the Kool Aid, Your Financial History. Your Business.]
article_img: bootstrap/img/dystopia.jpg
article_img_title: Nineteen Eighty-Four by George Orwell
article_img_alt: "An image from the movie Nineteen Eighty-Four"
reddit_url:
hn_url:
---
{% include JB/setup %}
<div class="intro">
  <div class="intro-txt">
    <p>
    Mainstream data analytics, at least in the "big data" sense, was once the reserve of business intelligence, marketing and speculative trading on the stock market but things are rapidly changing. For a lot of us, big data is about to become personal. Very personal indeed.
    </p>
    <p>
    People analytics, also referred to as workforce analytics, corporate analytics and HR analytics, is the application of big data to create behavioural and social profiles for individual people.
    </p>
    <p>
    Recruitment firms and some large employers have been using people analytics to qualify prospective candidates for quite some time, and some even have dedicated workforce analytics teams to monitor and analyse the activities of their staff. As with all things, the endless march of information technology is set to see this trend trickle down to all levels of employment in the future.
    </p>
  </div>
<div class="intro-img-border">
<div class="intro-img-bevel">
<div class="intro-img">
<img class="article-image" alt="{{page.article_img_title}}" title="{{page.article_img_title}}" src="{{ASSET_PATH}}/{{page.article_img}}"/>
</div>
</div>
</div>
</div>
<br/>
<br/>

#### People Analytics
In [a recent article in the Herald Sun newspaper][1] SCOUT Recruitment Software global business leader Andrea Tjoeng said the process, known as people analytics, could be mainstream in Australia within five years. _"It will be less about perfecting a CV and more about the footprint left behind in cyberspace"_ Ms Tjoeng said.

OK, in this day and age, everyone expects that employers will do some digging online, however, people analytics proves to be much more sinister. In addition to profiling potential employees using external data (public, paid-for, or otherwise), some employers continually profile existing staff using both external data and via analysis of internal social media, email, surveys, and the like, to define a prototypical "good employee" profile in order to employ people with similar profiles. And if an employee chooses not to use corporate social software? I have it on good authority one case where employees were told: _"Failure to engage with [crowd-sourcing software] can potentially be perceived in a negative light"_.

The bottom line is this: if you're filling out questionaires at work, using the corporate social networking tools, crowd-sourcing and ideation tools, using email, doing surveys, wikis, what have you, there may be additional reasons beyond engaging with staff, such as analysis and profiling. And, everything you're doing publicly online is bound to be used at some time in the future for profiling and analysis as well.

But really, that's all just tip of the iceburg stuff. According to an article in [The Atlantic][6], the Las Vegas casino Harrah’s tracks the smiles of the card dealers and waitstaff (its analytics team has quantified the impact of smiling on customer satisfaction) and Bloomberg logs every keystroke of every employee along with every time they enter and leave the premises according to [Business Insider Australia][5]. 

The people analytics software company [Gild][7] use an algorithm that scours the internet for open-source code in order to profile software engineers, and perhaps more alarmingly, the algorithm purportedly evaluates the code for its simplicity, elegance, documentation, and several other factors, including the frequency with which it’s been adopted by other programmers. Stack Overflow is also mined to analyse questions and answers by individuals and the breadth and popularity of that advice. Linkedin and Twitter are mined to analyse the language individuals use, and Gild have decided that certain phrases and words used in association with one another distinguishes expert software engineers from less skilled programmers. According to Gild, it knows _"these phrases and words are associated with good coding because it can correlate them with its evaluation of open-source code, and with the language and online behavior of programmers in good positions at prestigious companies"._ If you're a programmer and have ever used the internet, chances are that Gild has already compiled your "score".[^1]

There are many other workforce focussed analytics companies besides Gild such as Entelo and TalentBin, and it is unknown what data they may be collecting, how their algorithms analyse that data and what "score" they end up appointing you. Data collected about us and the profiles created from that data are not in our control.

Every day there is an insane amount of data being collected about people as they go about their off and online lives, and as time goes on, the types of, and rate of information collected will continue to grow. Do you even know what data is collected, stored, analysed and sold on by third party companies about you?
<br/>
<br/>

#### Causation 
In an [article in the New York Times][9], Data Scientist, Dr. Ming said of the algorithms she is now building for Gild: _"Let’s put everything in and let the data speak for itself"_.

Big data produces correlates, uncovers trends and probabilities, and finds weak bonds between data, amongst other things. "A correlates with B", in itself however, is not a legitimate form of argument and therefore the data can never _"speak for itself"_ because it is strictly quantitative. Correlation is simply not enough. Without causation there is no evidence to support any correlate (in big data or otherwise), and worse, can lead one to believe something that is not true. Spurious Correlations has compiled a [patently ridiculous example][11] of this which shows a 99.2% correlation between suicide by hanging, strangulation and suffocation in the US, and spending on science, space and technology.


some quote about correlates from gild or other (manga one is good)


People analytics does not provide causality. If there is no critical research to determine the causal mechanism that underlies correlations in data then there is no reason to believe that the result is anything other than mere coincidence. Determining causation from correlations and the causal nexus between them would be an almost impossible problem mathematically, so without empirical evidence showing a connection between cause and effect, a conclusion can not be drawn. Correlates can only direct us as to what questions to ask and which avenues to investigate, correlates cannot, without extensive investigation, be used in isolation to determine any "score" of any significance.
<br/>
<br/>





#### Systematic Bias
Big data, and especially people analytics suffers from the "N = all" fallacy. "N = all" simply means that the sample size is equivalent to population, and with regards to big data, it is this fallacy that produces the false assumption that sampling bias and uncertainty is reduced to zero. There are many other types of biases that are also inherent to big data, including inaccuracy of observation, incorrect measurement, algorithm and data calibration and drift.



an example like this, but not this! --------------------------
Why? If you, say, decided to compare women and men with the exact same qualifications that have been hired in the past, but then, looking into what happened next you learn that those women have tended to leave more often, get promoted less often, and give more negative feedback on their environments, compared to the men, your model might be tempted to hire the man over the woman next time the two showed up, rather than looking into the possibility that the company doesn’t treat female employees well.
-------------------------

how about, a predominately caucasian workforce, African americans, on the other hand, live further from the company than average and, on average leave the company after a shorter time than their caucasian peers. Should the people anaytics algorithm let this data speak for itself? Are these correlates enough to determine that a caucasian receives a higher "score"? Of course not. The question must be asked: _"Does the company have a racist culture in management that's directly causal to these effects?"_

an example about extroversion and social media... this will discriminate against introverts (and in some cases, introverts may be better suited to particular roles) and you need a mix of introverts and extroverts for a healthy team.

The interactive, social and behavioural models imposed by any platform (social, e-commerce, crowd sourced, whatever) will dictate who uses the platform, and how they use it. It stands to reason that this will necessarily taint the data collected and introduce systematic bias.


data exhaust
found data

Even the largest of datasets have bits of information missing.

necessary to exercise greater caution to be sure that big sample size does not lead to big inferential errors. Despite the advantages of big studies, large sample size can magnify the bias associated with error resulting from sampling or study design.

systematic bias has a component of modulation and mediation (services, recommenders, search result ranking, etc. modulate results because they steer us in particular directions)
Having all data on all people is an impossibility, pure and simple. 


systemtically biased decisions can further feed into more systematically biased decisions and you have a cumulative runaway bias inference increasing your bias with every decison made.




City officials might have thought they had found a way to record every pothole, but that wasn't the case. As Harford concluded: 'Some might think we are now able to measure everything; that we can turn everything into numbers. But we need to be wise enough to know that is always an illusion.'

"""
Consider Boston’s Street Bump smartphone app, which uses a phone’s accelerometer to detect potholes without the need for city workers to patrol the streets. As citizens of Boston download the app and drive around, their phones automatically notify City Hall of the need to repair the road surface. Solving the technical challenges involved has produced, rather beautifully, an informative data exhaust that addresses a problem in a way that would have been inconceivable a few years ago. The City of Boston proudly proclaims that the “data provides the City with real-time in­formation it uses to fix problems and plan long term investments.”

Yet what Street Bump really produces, left to its own devices, is a map of potholes that systematically favours young, affluent areas where more people own smartphones. Street Bump offers us “N = All” in the sense that every bump from every enabled phone can be recorded. That is not the same thing as recording every pothole. As Microsoft researcher Kate Crawford points out, found data contain systematic biases and it takes careful thought to spot and correct for those biases. Big data sets can seem comprehensive but the “N = All” is often a seductive illusion.
"""

<br/>
<br/>


#### Accuracy
The accuracy of "data exhaust" left behind by people in their online activities is highly questionable. 

Objectivity vs subjectivity.

Because found data sets are so messy, it can be hard to figure out what biases inaccuracies lurk inside them – and because they are so large. The behaviour and reporting of people is perhaps the least objective data possible. Are you actually friends with "all" the people and companies you've friended on facebook and twitter? If not, what are the types of relationships? Sarcasm? are you retweeting something because you agree or disagree? Your followers may know why, because they know you (presumably) but does an algorithm? Data does not speak for itself. Online surveys and competitions... do you answer them honestly? Linkedin... do you not embellish your qualifications and skills? Do other people not? Sign up for software or app trials? Do you use your real details?

truthiness of your self-reported data . This injects an insidious systematic error.
<br/>
<br/>









#### Privacy and Secrecy
Freedom of personal information and profiles generated and/or kept by corporate entities and government? Should one be allowed access to their own profile free of charge? Can one have their profile "removed" costs to obtain free info (court docs, FOI, scientific papers).

These aspects of people analytics provoke anxiety, of course. We would be wise to take legal measures to ensure, at a minimum, that companies can’t snoop where we have a reasonable expectation of privacy—and that any evaluations they might make of our professional potential aren’t based on factors that discriminate against classes of people.

Corporate analytics needs to be regulated to allow for a space for privacy and to ensure that people can consent to have their information mined.

will be tracked only for their suitability for their initial jobs, not for their potential.


Knowledge is power, if the power only flows one way then there will be control and abuse. The findings of the analytics on any potential employee (hired or not) should required to be share with that person, not only with the employer. For a modest fee (under $100) the analytics company should run that persons numbers through their system to determine the be job matches for them. Only then it can be equitable.

from anonymous marketing to personal intrusion (i.e. marketer doesn't care about the individual per-se, whereas with employers, that's all they care about).
before it was anonymous, now its personal.


what about skunkworks?




http://blog.hipchat.com/2014/04/25/hey-were-changing-our-terms-of-service/

Surveillance, for example, can inhibit such lawful activities as free speech, free association, and other First Amendment rights essential for democracy


Daniel Solov, ‘Why Privacy Matters Even if You Have ‘Nothing to Hide’

    “My life’s an open book,” people might say. “I’ve got nothing to hide.” But now the government has large dossiers of everyone’s activities, interests, reading habits, finances, and health. What if the government leaks the information to the public? What if the government mistakenly determines that based on your pattern of activities, you’re likely to engage in a criminal act? What if it denies you the right to fly? What if the government thinks your financial transactions look odd—even if you’ve done nothing wrong—and freezes your accounts? What if the government doesn’t protect your information with adequate security, and an identity thief obtains it and uses it to defraud you? Even if you have nothing to hide, the government can cause you a lot of harm.”
by Daniel J. Solove, Chronicle of Higher Education, “The Chronicle Review” (May 15, 2011) 




<br/>
<br/>



#### Innovation, Diversity and Serendipity

Cohen, Julie E., What Privacy Is For (November 5, 2012). Harvard Law Review, Vol. 126, 2013. Available at SSRN: http://ssrn.com/abstract=2175406

Innovation also requires room to tinker, and therefore thrives most fully in an environment that values and preserves spaces for tinkering. A society that permits the unchecked ascendancy of surveillance infrastructures, which dampen and modulate behavioral variability, cannot hope to maintain a vibrant tradition of cultural and technical innovation. Efforts to repackage pervasive surveillance as innovation — under the moniker “Big Data” —
are better understood as efforts to enshrine the methods and values
of the modulated society at the heart of our system of knowledge pro-
duction. The techniques of Big Data have important contributions to
make to the scientific enterprise and to social welfare, but as engines
of truth production about human subjects they deserve a long, hard
second look.


Innovative practice is threatened most
directly when circumstances impose intellectual regimentation, pre-
scribing orthodoxies and restricting the freedom to tinker. It thrives
most fully when circumstances yield serendipitous encounters with
new resources and ideas, and afford the intellectual and material
breathing room to experiment with them.48
breathing room to experiment with them.When the predicate conditions for innovation are described in this
way, the problem with characterizing privacy as anti-innovation be-
comes clear: it is modulation, not privacy, that poses the greater threat
to innovative practice. Regimes of pervasively distributed surveillance
and modulation seek to mold individual preferences and behavior in
ways that reduce the serendipity and the freedom to tinker on which
innovation thrives. The suggestion that innovative activity will persist
unchilled under conditions of pervasively distributed surveillance is
simply silly; it derives rhetorical force from the cultural construct of
the liberal subject, who can separate the act of creation from the fact
of surveillance. As we have seen, though, that is an unsustainable fic-
tion. The real, socially constructed subject responds to surveillance
quite differently — which is, of course, exactly why government and
commercial entities engage in it. Clearing the way for innovation re-
quires clearing the way for innovative practice by real people. Innova-
tive practice in turn requires breathing room for critical self-
determination and physical spaces within which the everyday practice
of tinkering can thrive.







"""
predictive rationality
"""
<br/>
<br/>


#### The age of Omnicient Surveillance
<br/>
<br/>


#### Compliance
With people analytics, correlations are drawn and judgements are made about our behavior and social skills, and statistical correlates are used to score our intelligence, quality of work, and probabilities of success or failure for particular tasks. However, in any form of real world analysis, finding correlations in data (big, disparate or otherwise) is only the _starting point_ of research, the process thereafter needs to establish whether those correlations present a causal relationship or are merely coincidental. People analytics is being sold as a turn-key solution to recruitment and human resources and is being touted as a substitute for, rather than a supplement to, observation and analysis.

Even if we can solve the problems of causal mechanism, systematic bias, and accuracy, is this a world we want to live in anyway? What are the negative social effects of reducing people to numbers calculated by an algorithm? Will people analytics result in a lack of employee diversity? Am I negatively affecting my "score" by publishing this article?

What makes people analytics particularly repugnant is the vast amount of stalking and invasion of privacy it allows corporations to engage in and its apparent acceptance as a normal business practise. 

The day will come where there will be an omni-present, ever churning array of algorithms watching and calculating the value of all employees, across all businesses, all of the time. What then? Keep your head down, do your work, follow the group, work is life.




... and in the same way that [Boston's street bump app falsely assumed n = all] so too do profiles produced by people analytics.
our perception, cognition, fairness, privacy and due process.

But big data do not solve the problem that has obsessed statisticians and scientists for centuries: the problem of insight, of inferring what is going on, and figuring out how we might intervene to change a system for the better.

in the exploration of this new frontier, there will be many speculations, experiments, trial, errors and it'll be everyday citizens who'll perform the role of guinea pig. There could be real-life dire consequences for those who are seen to fall outside the average, the norm.

sense of identity and self worth?

On the other hand, many times hiring managers are just looking for a reason to discard your resume to narrow down the talent pool. Anything negative gets you tossed. They see this. Maybe it's a good sign, maybe it's a bad sign. Either way it's something out of the ordinary that will take more time to evaluate. Better just toss the resume. There's still another stack of 100 candidates to go through...


According to its critics, Big Data is profiling on steroids, un-
thinkably intrusive and eerily omniscient.



Although the content of this article is mostly concerned with those in the programming community with regards to people analytics, it brings into question the ethics and morality of big data, private commoditisation and trading of dossiers on citizens, privacy and ultimately democracy itself.






<br/>
<br/>

#### Notes
[^1]: Gild ranks the quality of each programmer they analyse as a number between 1 and 100.


[1]:http://www.heraldsun.com.au/business/work/job-seekers-need-to-clean-up-their-digital-footprint-as-recruiters-look-through-computer-data/story-fnkjjdf8-1227299058334
[2]:http://www.thedailybeast.com/articles/2015/02/05/your-samsung-smarttv-is-spying-on-you-basically.html
[3]:http://www.washingtonpost.com/blogs/the-switch/wp/2015/03/11/privacy-advocates-try-to-keep-creepy-eavesdropping-hello-barbie-from-hitting-shelves
[4]:https://stallman.org/stallman-computing.html
[5]:http://www.businessinsider.com.au/bloomberg-scandal-culture-secrecy-spying-2013-5
[6]:http://www.theatlantic.com/magazine/archive/2013/12/theyre-watching-you-at-work/354681/
[7]:https://www.gild.com/
[9]:http://www.nytimes.com/2013/04/28/technology/how-big-data-is-playing-recruiter-for-specialized-workers.html?pagewanted=4&ref=business&pagewanted=all&_r=0
[11]:http://www.tylervigen.com/view_correlation?id=1597

