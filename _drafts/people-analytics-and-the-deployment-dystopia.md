---
layout: post
title: "People Analytics and the Big Data Dystopia"
description: "The dystopian future and the transition from freedom and employment to compliance and deployment thanks to big data and people analytics."
tagline: "future"
category: future
tags: [future, big data, analytics, employment, big brother, privacy, anonymity, compliance]
related: [Step Away From the Kool Aid, Your Financial History. Your Business.]
article_img: bootstrap/img/dystopia.jpg
article_img_title: Nineteen Eighty-Four by George Orwell
article_img_alt: "An image from the movie Nineteen Eighty-Four"
reddit_url:
hn_url:
---
{% include JB/setup %}
<div class="intro">
  <div class="intro-txt">
    <p>
    Mainstream data analytics, at least in the "big data" sense, was once the reserve of business intelligence, marketing and speculative trading on the stock market but things are rapidly changing. For a lot of us, big data is about to become personal. Very personal indeed.
    </p>
    <p>
    People analytics, also referred to as workforce analytics, corporate analytics and HR analytics, is the application of analytics on big data sets to create behavioural and social profiles for individual people.
    </p>
    <p>
    Recruitment firms and some large employers have been using people analytics to qualify prospective candidates for quite some time, and some even have dedicated workforce analytics teams to monitor and analyse the activities of their staff. As with all things, the endless march of information technology is set to see this trend trickle down to all levels of employment in the future.
    </p>
  </div>
<div class="intro-img-border">
<div class="intro-img-bevel">
<div class="intro-img">
<img class="article-image" alt="{{page.article_img_title}}" title="{{page.article_img_title}}" src="{{ASSET_PATH}}/{{page.article_img}}"/>
</div>
</div>
</div>
</div>
<br/>
<br/>

#### People Analytics
In [a recent article in the Herald Sun newspaper][1] SCOUT Recruitment Software global business leader Andrea Tjoeng said the process, known as people analytics, could be mainstream in Australia within five years. _"It will be less about perfecting a CV and more about the footprint left behind in cyberspace"_ Ms Tjoeng said.

OK, in this day and age, everyone expects that employers will do some digging online, however, people analytics proves to be much more sinister. In addition to profiling potential employees using external data (public, paid-for, or otherwise), some employers continually profile existing staff using both external data and via analysis of internal social media, email, surveys, and the like, to define a prototypical "good employee" profile in order to employ people with similar profiles. And if an employee chooses not to use corporate social software? I have it on good authority one case where employees were told: _"Failure to engage with [crowd-sourcing ideation software] can potentially be perceived in a negative light"_.

The bottom line is this: if you're filling out questionaires at work, using the corporate social networking tools, crowd-sourcing ideation tools, using email, doing surveys, what have you, there may be additional reasons beyond engaging with staff, such as analysis and profiling. And, everything you're doing publicly online is bound to be used at some time in the future for profiling and analysis.

But really, that's all just tip of the iceburg stuff. According to an article in [The Atlantic][6], the Las Vegas casino Harrah’s tracks the smiles of the card dealers and waitstaff (its analytics team has quantified the impact of smiling on customer satisfaction) and Bloomberg logs every keystroke of every employee along with every time they enter and leave the premises according to [Business Insider Australia][5]. The people analytics software company [Gild][7] use an algorithm that scours the internet for open-source code in order to profile software engineers, and perhaps more alarmingly, the algorithm purportedly evaluates the code for its simplicity, elegance, documentation, and several other factors, including the frequency with which it’s been adopted by other programmers. Stack Overflow is also mined to analyse questions and answers by individuals and the breadth and popularity of that advice. Linkedin and Twitter are mined to analyse the language individuals use, and Gild have decided that certain phrases and words used in association with one another distinguishes expert software engineers from less skilled programmers. According to Gild, it knows _"these phrases and words are associated with good coding because it can correlate them with its evaluation of open-source code, and with the language and online behavior of programmers in good positions at prestigious companies"_ [^1]. 

There are many other workforce focussed analytics companies like Gild such as Entelo and TalentBin, and it is unknown what data they may be collecting, how their algorithms analyse that data and what "score" they end up appointing you. Data collected about us and the profiles created from that data are not in our control.

Every single day there is an insane amount of data being collected about people as they go about both their off and online lives, and as time goes on, the types of, and rate of information collected will continue to grow. Do you even know what data is collected, stored and analysed by third party companies about you?
<br/>
<br/>












#### Coincidence and Correlation over Causation 
what is the difference? why is it bad?

"""
causal nexus
"""

1. What empirical evidence legitimizes a cause-effect connection? (acquisition)


http://www.tylervigen.com/view_correlation?id=1597
For example, the correlation between US spending on science, space, and technology and suicides by hanging, strangulation and suffocation is a remarkable 99.2% yet no one in their right mind would says that one causes the other.




“(People analytics determines) what makes up successful people, what patterns we can find and how we can use that to find similar people in the future.”
Um, no.



Analysis of big data produces correlates, uncovers trends, calculates probabilities and finds weak bonds between data points, amongst other things. What it does not provide however, is causality. Good programmers publish open source software and watch manga cartoons but is there causality anywhere in this conclusion? distinguishing cause and effect.


Correlations can easily lead one to believe something that is not true. Harvard Law School student and self-proclaimed statistical provocateur named Tyler Vigen (@TylerVigen) started a site called Spurious Correlations. Vigen has shown, for example, that there is an annual correlation between the number of people who have drowned by falling into a swimming pool and the number of films in which Nicolas Cage has appeared.

causal mechanism?

if there is no critical research to determine the causal mechanism that underlies correlations in data then there is no reason not to believe that the result is anything other than mere coincidence.

logically and mathematically determining the difference between correlation and causation is almost impossible. Empirical evidence via repeated observation and experimentation is the only way to tell.

"""
The inter-combination of Semantic Reasoning and advanced mathematical calculations has the potential to lead to disruptive marketplace capabilities. Avoiding spurious correlations and automatically finding causal factors contained in the mountains of data now being generated each and every day is going to be a game changer in the years ahead.
"""

random chance can often find a data variable that may appear causal



http://www.letitrain.com/blog/big-data-correlation-does-not-equal-causation/
"""
Google Flu Trends, which aggregates Google searches in an attempt to accurately predict flu activity, experienced a similar conundrum. In a Science magazine article published in March of 2014, researchers from Northeastern University and Harvard reported that Google’s flu-tracking service has consistently overestimated the number of flu cases in the United States. In addition, the algorithm completely missed the swine flu epidemic.

Although the researchers assert that “there are enormous scientific possibilities in big data,” they called Google Flu Trends an example of “big data hubris,” that is described as “the often implicit assumption that big data are a substitute for, rather than a supplement to, traditional data collection and analysis.”

But, this also doesn’t mean that it is entirely coincidental or that correlation doesn’t at least suggest causation. A strong correlation gives us a reason to dig deeper, albeit with a healthy dose of skepticism. Why, because there is a natural human tendency to give in to confirmation bias (a type of selective thinking whereby one tends to notice and look for information that confirms one’s own beliefs). Avoiding this bias requires not only critical thinking, but also actively seeking both supporting and contradictory evidence. Critical thinking and the application of sound scientific methods is something our team of pricing and data scientists take very seriously before formalizing new data sources into our revenue optimization algorithms.
"""


"""
Third factor C (the common-causal variable) causes both A and B
http://en.wikipedia.org/wiki/Spurious_relationship
All these examples deal with a lurking variable, which is simply a hidden third variable that affects both causes of the correlation; for example, the fact that it is summer in Example 3. A difficulty often also arises where the third factor, though fundamentally different from A and B, is so closely related to A and/or B as to be confused with them or very difficult to scientifically disentangle from them (see Example 4).

Example 1
    Sleeping with one's shoes on is strongly correlated with waking up with a headache.
    Therefore, sleeping with one's shoes on causes headache.

The above example commits the correlation-implies-causation fallacy, as it prematurely concludes that sleeping with one's shoes on causes headache. A more plausible explanation is that both are caused by a third factor, in this case going to bed drunk, which thereby gives rise to a correlation. So the conclusion is false.

Example 2
    Young children who sleep with the light on are much more likely to develop myopia in later life.
    Therefore, sleeping with the light on causes myopia.

This is a scientific example that resulted from a study at the University of Pennsylvania Medical Center. Published in the May 13, 1999 issue of Nature,[5] the study received much coverage at the time in the popular press.[6] However, a later study at Ohio State University did not find that infants sleeping with the light on caused the development of myopia. It did find a strong link between parental myopia and the development of child myopia, also noting that myopic parents were more likely to leave a light on in their children's bedroom.[7][8][9][10] In this case, the cause of both conditions is parental myopia, and the above-stated conclusion is false.


Example 3
    As ice cream sales increase, the rate of drowning deaths increases sharply.
    Therefore, ice cream consumption causes drowning.

The aforementioned example fails to recognize the importance of time and temperature in relationship to ice cream sales. Ice cream is sold during the hot summer months at a much greater rate than during colder times, and it is during these hot summer months that people are more likely to engage in activities involving water, such as swimming. The increased drowning deaths are simply caused by more exposure to water-based activities, not ice cream. The stated conclusion is false.


Example 4

    A hypothetical study shows a relationship between test anxiety scores and shyness scores, with a statistical r value (strength of correlation) of +.59.[11]
    Therefore, it may be simply concluded that shyness, in some part, causally influences test anxiety.

However, as encountered in many psychological studies, another variable, a "self-consciousness score", is discovered that has a sharper correlation (+.73) with shyness. This suggests a possible "third variable" problem, however, when three such closely related measures are found, it further suggests that each may have bidirectional tendencies (see "bidirectional variable", above), being a cluster of correlated values each influencing one another to some extent. Therefore, the simple conclusion above may be false.

Example 5

    Since the 1950s, both the atmospheric CO2 level and obesity levels have increased sharply.
    Hence, atmospheric CO2 causes obesity.

Richer populations tend to eat more food and consume more energy



Example 6

    HDL ("good") cholesterol is negatively correlated with incidence of heart attack.
    Therefore, taking medication to raise HDL decreases the chance of having a heart attack.

Further research[12] has called this conclusion into question. Instead, it may be that other underlying factors, like genes, diet and exercise, affect both HDL levels and the likelihood of having a heart attack; it is possible that medicines may affect the directly measurable factor, HDL levels, without affecting the chance of heart attack.




Much of scientific evidence is based upon a correlation of variables[18] – they are observed to occur together. Scientists are careful to point out that correlation does not necessarily mean causation. The assumption that A causes B simply because A correlates with B is often not accepted as a legitimate form of argument.

However, sometimes people commit the opposite fallacy – dismissing correlation entirely, as if it does not suggest causation at all. This would dismiss a large swath of important scientific evidence.[18] Since it may be difficult or ethically impossible to run controlled double-blind studies, correlational evidence from several different angles may be the strongest causal evidence available.[19] The combination of limited available methodologies with the dismissing correlation fallacy has on occasion been used to counter a scientific finding. For example, the tobacco industry has historically relied on a dismissal of correlational evidence to reject a link between tobacco and lung cancer.[20]

Correlation is a valuable type of scientific evidence in fields such as medicine, psychology, and sociology. But first correlations must be confirmed as real, and then every possible causative relationship must be systematically explored. In the end correlation can be used as powerful evidence for a cause-and-effect relationship between a treatment and benefit, a risk factor and a disease, or a social or economic factor and various outcomes. But it is also one of the most abused types of evidence, because it is easy and even tempting to come to premature conclusions based upon the preliminary appearance of a correlation.

Correlations are used in Bell's theorem to disprove local causality.


can you be discrimnated against, by proxy (high correlation between location and something else that leads to low score. what if the location is primarily made up of a minority race? is this correlation then a proxy for racial discrimination?

stuff about non-causality and behavioural profiles leading to discrimination (e.g. the manga thing would naturally discriminate against older workers, by proxy).


<br/>
<br/>














#### Systematic Bias
Big data, and especially people analytics suffer from the [N = All falacy][ref]. inaccuracy (as of observation or measurement) (imperfect calibration and drift) inherent in the system

http://www.nytimes.com/2013/04/28/technology/how-big-data-is-playing-recruiter-for-specialized-workers.html?pagewanted=4&ref=business&pagewanted=all&_r=0
“Let’s put everything in and let the data speak for itself,” Dr. Ming said of the algorithms she is now building for Gild.
Why? If you, say, decided to compare women and men with the exact same qualifications that have been hired in the past, but then, looking into what happened next you learn that those women have tended to leave more often, get promoted less often, and give more negative feedback on their environments, compared to the men, your model might be tempted to hire the man over the woman next time the two showed up, rather than looking into the possibility that the company doesn’t treat female employees well.

In other words, ignoring causation can be a flaw, rather than a feature. Models that ignore causation can add to historical problems instead of addressing them. And data doesn’t speak for itself, data is just a quantitative, pale echo of the events of our society.

Dr. Ming doesn’t suggest eliminating human judgment, but she does think that the computer should lead the way, acting as an automated vacuum and filter for talent. The company has amassed a database of seven million programmers, ranking them based on what it calls a Gild score — a measure, the company says, of what a person can do. Ultimately, Dr. Ming wants to expand the algorithm so it can search for and assess other kinds of workers, like Web site designers, financial analysts and even sales people at, say, retail outlets.














... and in the same way that [Boston's street bump app falsely assumed n = all] so too do people analytics.















‘N = all’ means that the sample equals the population. It implies that the uncertainty
generated by the jump from sample to population is absent in the case of Big Data.
Or, more moderately formulated, it means that the exponential increase of ‘n’


our perception, cognition, fairness, privacy and due process.




Another way in which the assumption that N=ALL can matter is that it often gets translated into the idea that data is objective

City officials might have thought they had found a way to record every pothole, but that wasn't the case. As Harford concluded: 'Some might think we are now able to measure everything; that we can turn everything into numbers. But we need to be wise enough to know that is always an illusion.'

Harford began by very clearly defining what he meant by big data, at least in the context of this talk. The data he was referring to was 'found data', the type that's created when our mobile phones ping mobile phone masts, when we update Facebook, search the web or tweet our frustrations about a particular story in the news.

Hidden biases in data are a problem. Even the largest of datasets have bits of information missing. Quoting Microsoft researcher Kate Crawford, Harford said one might think they have all the data, but there will always be people missing from any dataset.

unlike the ‘big data’ ideal, N doesn’t equal all.

But it illustrates the pitfalls of relying on ‘data exhaust’ and assuming that N=all. A huge amount of data is input by users of social networks like Facebook and Twitter or internet companies like Amazon and Google and plenty are eager to explore the insights that it might reveal. But it’s important to remember that at every stage who is using those services and what data are left behind will be determined by the nature of the platform itself.


That second point often provides the basis for a big lie about big data—quantity improves quality. In other words, people falsely believe big data has fewer data quality issues since larger data sets have smaller margins of error. Or stated more succinctly: more data, less statistical error.

However, there are plenty of other errors that creep into data that aren’t statistical in nature. “A more insidious kind of error,” Seife explained, “is systematic error. Unlike statistical error, systematic error doesn’t diminish as the sample size grows.” One systematic error I have discussed in a previous post is sampling bias, which is when a sample, regardless of how big it is, isn’t randomly collected but instead reflects a deep data collection bias that skews the statistical results toward a false conclusion.

information might lead to systematic bias against whole classes of people
different neighborhoods and towns can have different racial profiles

Because found data sets are so messy, it can be hard to figure out what biases lurk inside them – and because they are so large, some analysts seem to have decided the sampling problem isn’t worth worrying about. It is.

"""
Professor Viktor Mayer-Schönberger of Oxford’s Internet Institute, co-author of Big Data, told me that his favoured definition of a big data set is one where “N = All” – where we no longer have to sample, but we have the entire background population. Returning officers do not estimate an election result with a representative tally: they count the votes – all the votes. And when “N = All” there is indeed no issue of sampling bias because the sample includes everyone.

But is “N = All” really a good description of most of the found data sets we are considering? Probably not. “I would challenge the notion that one could ever have all the data,” says Patrick Wolfe, a computer scientist and professor of statistics at University College London.


An example is Twitter. It is in principle possible to record and analyse every message on Twitter and use it to draw conclusions about the public mood. (In practice, most researchers use a subset of that vast “fire hose” of data.) But while we can look at all the tweets, Twitter users are not representative of the population as a whole. (According to the Pew Research Internet Project, in 2013, US-based Twitter users were disproportionately young, urban or suburban, and black.)

There must always be a question about who and what is missing, especially with a messy pile of found data. Kaiser Fung, a data analyst and author of Numbersense, warns against simply assuming we have everything that matters. “N = All is often an assumption rather than a fact about the data,” he says.

Consider Boston’s Street Bump smartphone app, which uses a phone’s accelerometer to detect potholes without the need for city workers to patrol the streets. As citizens of Boston download the app and drive around, their phones automatically notify City Hall of the need to repair the road surface. Solving the technical challenges involved has produced, rather beautifully, an informative data exhaust that addresses a problem in a way that would have been inconceivable a few years ago. The City of Boston proudly proclaims that the “data provides the City with real-time in­formation it uses to fix problems and plan long term investments.”

Yet what Street Bump really produces, left to its own devices, is a map of potholes that systematically favours young, affluent areas where more people own smartphones. Street Bump offers us “N = All” in the sense that every bump from every enabled phone can be recorded. That is not the same thing as recording every pothole. As Microsoft researcher Kate Crawford points out, found data contain systematic biases and it takes careful thought to spot and correct for those biases. Big data sets can seem comprehensive but the “N = All” is often a seductive illusion.

But big data do not solve the problem that has obsessed statisticians and scientists for centuries: the problem of insight, of inferring what is going on, and figuring out how we might intervene to change a system for the better.

“We have a new resource here,” says Professor David Hand of Imperial College London. “But nobody wants ‘data’. What they want are the answers.”
"""


then there is an accuracy problem with data....

While “lies, damn lies, and statistics” is common data-bashing refrain uttered by people who don’t like what statistics are showing them, people are another significant source of systematic error. More precisely, lying people. Before you set your pants on fire by claiming not to be a liar, consider the following examples:

    Are you really “friends” with the people you connect with or customers of the products and services you “like” on social networking websites?
    Do you really read the books you review on Amazon or the content you re-tweet on Twitter?
    When you complete an online survey (e.g., for a chance to win a new iPhone or iPad), do you honestly answers questions like “Annual family income”?
    Do all of the job titles and keywords in your LinkedIn profile reflect your actual professional experience?  (Just in case anyone asks, I was a Vice President at Vandelay Industries.)
    When you sign up for a free trial of a web service or download a white paper, do you provide an active email address or select the country you actually live in from the drop-down list?

Well, maybe you don’t tell lies, but at the very least you have to admit that the truthiness of your self-reported data makes it rather quality-ish. This injects an insidious systematic error into the volume and variety of data fed into the statistical analysis being applied to an increasing number of business areas including market segmentation, campaign effectiveness, consumer behavior, sales forecasting, and sentiment analysis.






in the exploration of this new frontier, there will be many speculations, experiments, trial, errors and it'll be everyday citizens who'll perform the role of guinea pig. There could be real-life dire consequences for those who are seen to fall outside the average, the norm.

On the other hand, many times hiring managers are just looking for a reason to discard your resume to narrow down the talent pool. Anything negative gets you tossed. They see this. Maybe it's a good sign, maybe it's a bad sign. Either way it's something out of the ordinary that will take more time to evaluate. Better just toss the resume. There's still another stack of 100 candidates to go through...


sense of identity and self worth?


necessary to exercise greater caution to be sure that big sample size does not lead to big inferential errors. Despite the advantages of big studies, large sample size can magnify the bias associated with error resulting from sampling or study design.



<br/>
<br/>



#### Rights to privacy and freedom of information
Freedom of personal information and profiles generated and/or kept by corporate entities and government? Should one be allowed access to their own profile free of charge? Can one have their profile "removed" costs to obtain free info (court docs, FOI, scientific papers).

These aspects of people analytics provoke anxiety, of course. We would be wise to take legal measures to ensure, at a minimum, that companies can’t snoop where we have a reasonable expectation of privacy—and that any evaluations they might make of our professional potential aren’t based on factors that discriminate against classes of people.

Corporate analytics needs to be regulated to allow for a space for privacy and to ensure that people can consent to have their information mined.

will be tracked only for their suitability for their initial jobs, not for their potential.


Knowledge is power, if the power only flows one way then there will be control and abuse. The findings of the analytics on any potential employee (hired or not) should required to be share with that person, not only with the employer. For a modest fee (under $100) the analytics company should run that persons numbers through their system to determine the be job matches for them. Only then it can be equitable.

from anonymous marketing to personal intrusion (i.e. marketer doesn't care about the individual per-se, whereas with employers, that's all they care about).
before it was anonymous, now its personal.



Cohen, Julie E., What Privacy Is For (November 5, 2012). Harvard Law Review, Vol. 126, 2013. Available at SSRN: http://ssrn.com/abstract=2175406

Innovation also requires room to
tinker, and therefore thrives most fully in an environment that values
and preserves spaces for tinkering. A society that permits the un-
checked ascendancy of surveillance infrastructures, which dampen and
modulate behavioral variability, cannot hope to maintain a vibrant tra-
dition of cultural and technical innovation. Efforts to repackage per-
vasive surveillance as innovation — under the moniker “Big Data” —
are better understood as efforts to enshrine the methods and values
of the modulated society at the heart of our system of knowledge pro-
duction. The techniques of Big Data have important contributions to
make to the scientific enterprise and to social welfare, but as engines
of truth production about human subjects they deserve a long, hard
second look.

tween freedom and constraint. Innovative practice is threatened most
directly when circumstances impose intellectual regimentation, pre-
scribing orthodoxies and restricting the freedom to tinker. It thrives
most fully when circumstances yield serendipitous encounters with
new resources and ideas, and afford the intellectual and material
breathing room to experiment with them.48
When the predicate conditions for innovation are described in this

According to its critics, Big Data is profiling on steroids, un-
thinkably intrusive and eerily omniscient.

But those tech-
niques cannot themselves decide which questions to investigate, cannot
instruct us how to place data flows and patterns in larger conceptual
or normative perspective, and cannot tell us whether and when it
might be fair and just to limit data processing in the service of other
values. These shortcomings mean that Big Data cannot replace either
human-driven modeling or the prior decisions about direction and
scope that set the substantive and ethical parameters for particular
programs of investigation.


"""
predictive rationality
"""





<br/>
<br/>



#### Behavioural and Social Compliance
With people analytics, correlations are drawn and judgements are made about our behavior and social skills, and statistical correlates are used to score our intelligence, quality of work, and probabilities of success or failure for particular tasks. However, in any form of real world analysis, finding correlations in data (big, disparate or otherwise) is only the _starting point_ of research, the process thereafter needs to establish whether those correlations present a causal relationship or are merely coincidental. People analytics is being sold as a turn-key solution to recruitment and human resources and is being touted as a substitute for, rather than a supplement to, observation and analysis.

Even if we can solve the causal mechanism, systematic bias, and accuracy problems, is this a world we want to live in anyway? What are the negative social effects of reducing people to numbers calculated by an algorithm? Will people analytics result in a lack of employee diversity? Am I negatively affecting my "score" by publishing this article?

What makes people analytics particularly repugnant is the vast amount of stalking and invasion of privacy it allows corporations to engage in and its apparent acceptance as a normal business practise. 


The day will come where there will be an omni-present, ever churning array of algorithms watching and calculating the value of all employees, across all businesses, all of the time. What then? Keep your head down, do your work, follow the group, work is life.
<br/>
<br/>

#### Notes
[^1]: Gild ranks the quality of each programmer they analyse as a number between 1 and 100.


[1]:http://www.heraldsun.com.au/business/work/job-seekers-need-to-clean-up-their-digital-footprint-as-recruiters-look-through-computer-data/story-fnkjjdf8-1227299058334
[2]:http://www.thedailybeast.com/articles/2015/02/05/your-samsung-smarttv-is-spying-on-you-basically.html
[3]:http://www.washingtonpost.com/blogs/the-switch/wp/2015/03/11/privacy-advocates-try-to-keep-creepy-eavesdropping-hello-barbie-from-hitting-shelves
[4]:https://stallman.org/stallman-computing.html
[5]:http://www.businessinsider.com.au/bloomberg-scandal-culture-secrecy-spying-2013-5
[6]:http://www.theatlantic.com/magazine/archive/2013/12/theyre-watching-you-at-work/354681/
[7]:https://www.gild.com/


