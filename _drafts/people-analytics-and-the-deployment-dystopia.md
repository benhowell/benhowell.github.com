---
layout: post
title: "People Analytics and the Deployment Dystopia"
description: "The dystopian future and the transition from freedom and employment to compliance and deployment thanks to big data and people analytics."
tagline: "future"
category: future
tags: [future, big data, analytics, IoT, employment, big brother, privacy, anonymity, freedom, compliance]
related: [Step Away From the Kool Aid, Your Financial History. Your Business.]
article_img: bootstrap/img/dystopia.jpg
article_img_title: Nineteen Eighty-Four by George Orwell
article_img_alt: "An image from the movie Nineteen Eighty-Four"
reddit_url:
hn_url:
---
{% include JB/setup %}
<div class="intro">
  <div class="intro-txt">
    <p>
    Data analytics, at least in the "big data" sense, was once the reserve of Business Intelligence, marketing and speculative trading on the stock market but things are rapidly changing. For a lot of us, big data is about to become personal. Very personal indeed.
    </p>
    <p>
    People analytics (sometimes called "workforce analytics" and "corporate analytics"), as the name suggests, is the application of analytics on big data sets to create behavioural and social profiles for individual people.
    </p>
  </div>
<div class="intro-img-border">
<div class="intro-img-bevel">
<div class="intro-img">
<img class="article-image" alt="{{page.article_img_title}}" title="{{page.article_img_title}}" src="{{ASSET_PATH}}/{{page.article_img}}"/>
</div>
</div>
</div>
</div>
<br/>
<br/>









#### People Analytics
what is it? who uses it? what are some example conclusions?

Recruitment firms and some large employers are already using big data to qualify prospective candidates and some of the larger corporations have dedicated workforce analytics teams to monitor and analyse the activities of their employees, as well as those of prospective employees. As with all things, the endless march of information technology is set to see this trend trickle down to all levels of employment in the future.



SCOUT Recruitment Software global business leader Andrea Tjoeng said the process, known as people analytics, could be mainstream in Australia within five years.



In [a recent article in the Herald Sun newspaper][1] SCOUT Recruitment Software global business leader Andrea Tjoeng said:

“It will be less about perfecting a CV and more about the footprint left behind in cyberspace,” she said.

“If you’re reviewing something on Whirlpool, think how that might be read by a prospective employer.

“When you are sharing anything about yourself, think whether you would share that information on your first day or in a job interview.”

Ok, well we sort of expect that employers will do a little digging online, however, the automated data analytics version is much more sinister:

The most common form of people analytics creates a profile of the company’s best employees based on staff surveys then applies the profile to new candidates during the application process to find people who are similar.

“They might look for patterns like having lots of experience in a certain role, or living within a 10km radius of the office, or (whether) that kind of person tends to enjoy researching and doing their own self-guided learning on the weekend,” Ms Tjoeng said.

“(People analytics determines) what makes up successful people, what patterns we can find and how we can use that to find similar people in the future.”
There are predicted to be both positive and negative social effects of reducing jobseekers down to a number from an algorithm.
Ms Tjoeng said the process had led to a lack of employee diversity in Silicon Valley.

“Big data showed previous experience had no bearing on whether an employee was going to succeed at xerox. It was more about cultural fit and how close they live to the office,” Ms Tjoeng said.

Big data can include keywords in resumes and answers on company questionnaires but increasingly, digital footprints also contribute.
Ms Tjoeng said a lot of the data collected for employee profiles might not be in our control.
“Assume any information you are sharing online, even if it is not public now, in a few years it will be,” she said.
“This is a natural evolution as our technology improves and we become more comfortable sharing our lives online.”


Hays director Darren Buchanan said big data and people analytics could also identify triggers for employees leaving their company, such as time served or reaching a certain level.
“It can be used as a flag to take some action, change behaviour or put in support structures to help people get through that period or help them take the next step forward to where they want to go,” he says.
Mr Buchanan said big data should not be used in isolation but as an extra tool to build a bigger picture.
“Like psychometric testing … (people analytics) is a component of the recruitment process rather than the be all and end all of it,” he said.
“It will never replace personal interactions.”

Xerox still interviews all candidates in person before deciding to hire them, Morse told me, but, she added, “We’re getting to the point where some of our hiring managers don’t even want to interview anymore”—they just want to hire the people with the highest scores.

There are some data that Evolv simply won’t use, out of a concern that the information might lead to systematic bias against whole classes of people. The distance an employee lives from work, for instance, is never factored into the score given each applicant, although it is reported to some clients. That’s because different neighborhoods and towns can have different racial profiles, which means that scoring distance from work could violate equal-employment-opportunity standards. Marital status? Motherhood? Church membership? “Stuff like that,” Meyerle said, “we just don’t touch”—at least not in the U.S., where the legal environment is strict. Meyerle told me that Evolv has looked into these sorts of factors in its work for clients abroad, and that some of them produce “startling results.” Citing client confidentiality, he wouldn’t say more.

For a sense of what the future of people analytics may bring, I turned to Sandy Pentland, the director of the Human Dynamics Laboratory at MIT. In recent years, Pentland has pioneered the use of specialized electronic “badges” that transmit data about employees’ interactions as they go about their days. The badges capture all sorts of information about formal and informal conversations: their length; the tone of voice and gestures of the people involved; how much those people talk, listen, and interrupt; the degree to which they demonstrate empathy and extroversion; and more. Each badge generates about 100 data points a minute.

Bloomberg reportedly logs every keystroke of every employee, along with their comings and goings in the office. The Las Vegas casino Harrah’s tracks the smiles of the card dealers and waitstaff on the floor (its analytics team has quantified the impact of smiling on customer satisfaction). E‑mail, of course, presents an especially rich vein to be mined for insights about our productivity, our treatment of co-workers, our willingness to collaborate or lend a hand, our patterns of written language, and what those patterns reveal about our intelligence, social skills, and behavior. As technologies that analyze language become better and cheaper, companies will be able to run programs that automatically trawl through the e-mail traffic of their workforce, looking for phrases or communication patterns that can be statistically associated with various measures of success or failure in particular roles.

Perhaps the most exotic development in people analytics today is the creation of algorithms to assess the potential of all workers, across all companies, all the time.


https://www.gild.com/
what others?

In a small conference room, we were shown a digital map of Northwest Washington, D.C., home to The Atlantic. Little red pins identified all the coders in the area who were proficient in the skills that an Atlantic Media job announcement listed as essential. Next to each pin was a number that ranked the quality of each coder on a scale of one to 100, based on the mix of skills Atlantic Media was looking for. (No one with a score above 75, we were told, had ever failed a coding test by a Gild client.) If we’d wished, we could have zoomed in to see how The Atlantic’s own coders scored.

The way Gild arrives at these scores is not simple. The company’s algorithms begin by scouring the Web for any and all open-source code, and for the coders who wrote it. They evaluate the code for its simplicity, elegance, documentation, and several other factors, including the frequency with which it’s been adopted by other programmers. For code that was written for paid projects, they look at completion times and other measures of productivity. Then they look at questions and answers on social forums such as Stack Overflow, a popular destination for programmers seeking advice on challenging projects. They consider how popular a given coder’s advice is, and how widely that advice ranges.

The algorithms go further still. They assess the way coders use language on social networks from LinkedIn to Twitter; the company has determined that certain phrases and words used in association with one another can distinguish expert programmers from less skilled ones. Gild knows these phrases and words are associated with good coding because it can correlate them with its evaluation of open-source code, and with the language and online behavior of programmers in good positions at prestigious companies.

Here’s the part that’s most interesting: having made those correlations, Gild can then score programmers who haven’t written open-source code at all, by analyzing the host of clues embedded in their online histories. They’re not all obvious, or easy to explain. Vivienne Ming, Gild’s chief scientist, told me that one solid predictor of strong coding is an affinity for a particular Japanese manga site.

Why would good coders (but not bad ones) be drawn to a particular manga site? By some mysterious alchemy, does reading a certain comic-book series improve one’s programming skills? “Obviously, it’s not a causal relationship,” Ming told me. But Gild does have 6 million programmers in its database, she said, and the correlation, even if inexplicable, is quite clear.

http://www.theatlantic.com/magazine/archive/2013/12/theyre-watching-you-at-work/354681/

if you're filling out questionaires at work, using the corporate social networking tools (yammer, etc.), crowd-sourcing ideation tools, email, doing surveys, etc, there may be other "unspoken" reasons ... they're analysing you. 

These aspects of people analytics provoke anxiety, of course. We would be wise to take legal measures to ensure, at a minimum, that companies can’t snoop where we have a reasonable expectation of privacy—and that any evaluations they might make of our professional potential aren’t based on factors that discriminate against classes of people.

But there is another side to this. People analytics will unquestionably provide many workers with more options and more power. Gild, for example, helps companies find undervalued software programmers, working indirectly to raise those people’s pay. Other companies are doing similar work. One called Entelo, for instance, specializes in using algorithms to identify potentially unhappy programmers who might be receptive to a phone call (because they’ve been unusually active on their professional-networking sites, or because there’s been an exodus from their corner of their company, or because their company’s stock is tanking). As with Gild, the service benefits the worker as much as the would-be employer.

Gild plans to let programmers see their own profiles and take skills challenges to try to improve their scores. 

Ultimately, all of these new developments raise philosophical questions. As professional performance becomes easier to measure and see, will we become slaves to our own status and potential, ever-focused on the metrics that tell us how and whether we are measuring up? Will too much knowledge about our limitations hinder achievement and stifle our dreams? 



Corporate analytics needs to be regulated to allow for a space for privacy and to ensure that people can consent to have their information mined.

will be tracked only for their suitability for their initial jobs, not for their potential.


Knowledge is power, if the power only flows one way then there will be control and abuse. The findings of the analytics on any potential employee (hired or not) should required to be share with that person, not only with the employer. For a modest fee (under $100) the analytics company should run that persons numbers through their system to determine the be job matches for them. Only then it can be equitable.



big brother, people analytics, vanilla drone compartmental persona and life, just to be chosen by a corp/employer... otherwise unemployable.

Code for "be a good drone, do not step outside your stall, work is your life, don't have an independent thought" It's a good thing I have given up any ambition to stick my head up any bosses butt on the corporate ladder. The sad thing is I actually thought about whether to post this or not.

sense of identity and self worth?

in the exploration of this new frontier, there will be many speculations, experiments, trial, errors and it'll be everyday citizens who'll perform the role of guinea pig. There could be real-life dire consequences for those who are seen to fall outside the average, the norm.

On the other hand, many times hiring managers are just looking for a reason to discard your resume to narrow down the talent pool. Anything negative gets you tossed. They see this. Maybe it's a good sign, maybe it's a bad sign. Either way it's something out of the ordinary that will take more time to evaluate. Better just toss the resume. There's still another stack of 100 candidates to go through...

You may even get emails telling you that "your non use of the corporate social media thingo will be looked upon negatively"


Freedom of personal information and profiles generated and/or kept by corporate entities and government? Should one be allowed access to their own profile free of charge? Can one have their profile "removed" costs to obtain free info (court docs, FOI, scientific papers).

Will we have to avoid capture of practically all personal data and tracking of our movements and become a digital recluse, just like [RMS][4]? Or will that very act and the forensic evidence it does or conversely, does not leave behind be used against us by our future people analytics algorithmic overlords?

Is such personal intrusion ethically and morally defensible by anyone? Do we even have a right to privacy anymore? Will analytical profiling using the full gamut of day to day personal data of ones activities become commonplace by all and sundry? We already live in a world where automated analysis of this data is used to personally target advertising. We're very quickly approaching a world where automated "people analysis" will be used to determine employability. There is no end to how and where personal profiling can be used in business and law enforcement.
<br/>
<br/>


#### from anonymous marketing to personal intrusion (i.e. marketer doesn't care about the individual per-se, whereas with employers, that's all they care about).
before it was anonymous, now its personal.

<br/>
<br/>

#### Coincidence and Correlation over Causation 
what is the difference? why is it bad?

An advantage of having knowledge about causal relationships rather than about statistical associations is that the former enables prediction of the effects of actions that perturb the observed system,” assert Joris M. Mooij, 
Analysis of big data produces correlates, uncovers trends, calculates probabilities and finds weak bonds between data points, amongst other things. What it does not provide however, is causality. Good programmers publish open source software and watch manga cartoons but is there causality anywhere in this conclusion? distinguishing cause and effect.


Correlations can easily lead one to believe something that is not true. To drive this point home with a bit of humor, a Harvard Law School student and self-proclaimed statistical provocateur named Tyler Vigen (@TylerVigen) started a site called Spurious Correlations. Vigen has shown, for example, that there is an annual correlation between the number of people who have drowned by falling into a swimming pool and the number of films in which Nicolas Cage has appeared and that the divorce rate in Maine correlates to the per capita consumption of margarine in the United States. Unilever, manufacturer of “I Can’t Believe It’s Not Butter!”, and other manufacturers of margarine are pretty certain they are not contributing to broken marriages in Maine. In the following 3-minute video, Vigen does a good job of explaining the difference between correlation and causation without going into any mathematics.

causal mechanism?

if there is no critical research to determine the causal mechanism that underlies correlations in data then there is no reason to believe that the result is mere coincidence.

logically and mathematically determining the difference between correlation and causation is almost impossible. Empirical evidence via repeated observation and experimentation is the only way to tell.

"""
The inter-combination of Semantic Reasoning and advanced mathematical calculations has the potential to lead to disruptive marketplace capabilities. Avoiding spurious correlations and automatically finding causal factors contained in the mountains of data now being generated each and every day is going to be a game changer in the years ahead.
"""

random chance can often find a data variable that may appear causal



http://www.letitrain.com/blog/big-data-correlation-does-not-equal-causation/
"""
Google Flu Trends, which aggregates Google searches in an attempt to accurately predict flu activity, experienced a similar conundrum. In a Science magazine article published in March of 2014, researchers from Northeastern University and Harvard reported that Google’s flu-tracking service has consistently overestimated the number of flu cases in the United States. In addition, the algorithm completely missed the swine flu epidemic.

Although the researchers assert that “there are enormous scientific possibilities in big data,” they called Google Flu Trends an example of “big data hubris,” that is described as “the often implicit assumption that big data are a substitute for, rather than a supplement to, traditional data collection and analysis.”

But, this also doesn’t mean that it is entirely coincidental or that correlation doesn’t at least suggest causation. A strong correlation gives us a reason to dig deeper, albeit with a healthy dose of skepticism. Why, because there is a natural human tendency to give in to confirmation bias (a type of selective thinking whereby one tends to notice and look for information that confirms one’s own beliefs). Avoiding this bias requires not only critical thinking, but also actively seeking both supporting and contradictory evidence. Critical thinking and the application of sound scientific methods is something our team of pricing and data scientists take very seriously before formalizing new data sources into our revenue optimization algorithms.
"""




<br/>
<br/>

#### Discrimination by proxy
can you be discrimnated against, by proxy (high correlation between location and something else that leads to low score. what if the location is primarily made up of a minority race? is this correlation then a proxy for racial discrimination?

stuff about non-causality and behavioural profiles leading to discrimination (e.g. the manga thing would naturally discriminate against older workers, by proxy).





<br/>
<br/>

#### Behavioural and Social Compliance
conclusion

Compliance by law to live and express ones self in a certain way and perform certain functions as an online citizen being enforced by law is the prototypical dystopian nightmare that provides great material for science fiction. I don't believe that that will be the future for us. More realistically however, I believe there may be a future where a certain uncomfortable level of compliance is subversively enforced by social pressure, due, in part, to corporate algorithms deeming your employable worth if you do not comply. If you think this seems far fetched, just read any thread on any tech forum involving the topic of employment with regard to programmers. An often parroted requirement for employment as a programmer by a range of different people and/or companies is that a prospective employee spend their free time on public "side projects" (github repositories, whatever), as if one's entire life must be spent honing their craft. What about hobbies? Well, programming of course. See profiling and compliance is already happening, albeit analysed manually.

More and more decisions that affect our lives will be made by profiling algorithms. get used to it. 

Even if we can solve the "causal mechanism problem", is this really a world we want to live in? is it ethical?

So will we have to carefully craft our personal public brand at all times? Will we end up living in a world where we have to "act" as our profession at all times, both at work and at home, offline and online? Computer might say "yes".


[1]:http://www.heraldsun.com.au/business/work/job-seekers-need-to-clean-up-their-digital-footprint-as-recruiters-look-through-computer-data/story-fnkjjdf8-1227299058334
[2]:http://www.thedailybeast.com/articles/2015/02/05/your-samsung-smarttv-is-spying-on-you-basically.html
[3]:http://www.washingtonpost.com/blogs/the-switch/wp/2015/03/11/privacy-advocates-try-to-keep-creepy-eavesdropping-hello-barbie-from-hitting-shelves
[4]:https://stallman.org/stallman-computing.html